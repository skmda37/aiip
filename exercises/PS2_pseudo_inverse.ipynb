{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d3370-8442-4dd8-831b-5754cea61085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8834d73-9313-49a9-8ece-2fbce0947f2e",
   "metadata": {},
   "source": [
    "# Pseudo-Inverse and Singular Value Decomposition\n",
    "Task: Implement the pseudo-inverse using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece4626-ac06-4d98-9d64-c11b5f423958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pseudoinverse(K, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the Moore-Penrose pseudo-inverse of a matrix using SVD.\n",
    "    \n",
    "    The pseudo-inverse is useful for solving linear systems when the matrix\n",
    "    is not invertible. Small singular values below the tolerance are treated as zero.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    K : ndarray\n",
    "        Input matrix (2D array) to compute the pseudo-inverse for\n",
    "    tol : float, optional\n",
    "        Relative tolerance for considering singular values as zero.\n",
    "        Singular values < tol * s[0] will be treated as zero (default: 1e-10)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    K_dagger : ndarray\n",
    "        Pseudo-inverse of K with same shape as K.T\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    The pseudo-inverse should satisfy these properties:\n",
    "    1. K @ K_dagger @ K ≈ K\n",
    "    2. K_dagger @ K @ K_dagger ≈ K_dagger\n",
    "    3. (K @ K_dagger).T ≈ K @ K_dagger\n",
    "    4. (K_dagger @ K).T ≈ K_dagger @ K\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    assert isinstance(K, np.ndarray), \"Input must be a numpy array\"\n",
    "    assert K.ndim == 2, \"Input must be a 2D matrix\"\n",
    "    \n",
    "    # TODO: Compute the SVD of K\n",
    "    # Hint: Use np.linalg.svd with full_matrices=False\n",
    "    # U, s, Vh = ...\n",
    "    \n",
    "    # TODO: Identify which singular values are considered non-zero\n",
    "    # The threshold should be relative to the largest singular value (s[0])\n",
    "    # nonzero_idx = ...\n",
    "    \n",
    "    # TODO: Compute the reciprocal of non-zero singular values\n",
    "    # Remember to avoid division by zero for small singular values\n",
    "    # s_inv = ...\n",
    "    \n",
    "    # TODO: Construct the pseudo-inverse matrix\n",
    "    # Remember the formula: Vh^H @ diag(s_inv) @ U^H\n",
    "    # K_dagger = ...\n",
    "    \n",
    "    return K_dagger  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d4eda-c8a3-44f9-b458-64122139d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_pseudoinverse_properties():\n",
    "    \"\"\"\n",
    "    Verify the four key Moore-Penrose properties of the pseudo-inverse.\n",
    "    \n",
    "    Students should complete the missing verification steps and interpret the results.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility (students can change this)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create a test matrix (rectangular to make it interesting)\n",
    "    m, n = 8, 5  # m > n, overdetermined system\n",
    "    K = np.random.randn(m, n)\n",
    "    print(f\"Testing with {m}x{n} matrix\")\n",
    "    \n",
    "    # TODO 1: Compute the pseudo-inverse using your function\n",
    "    # K_dagger = ...\n",
    "    \n",
    "    # Property 1: K K† K should equal K\n",
    "    # TODO 2: Compute KKdaggerK and compare to original K\n",
    "    # KKdaggerK = ...\n",
    "    # property1 = np.allclose(...)\n",
    "    \n",
    "    # Property 2: K† K K† should equal K†\n",
    "    # TODO 3: Compute KdaggerKKdagger and compare to K_dagger\n",
    "    # KdaggerKKdagger = ...\n",
    "    # property2 = np.allclose(...)\n",
    "    \n",
    "    # Property 3: (K K†) should be Hermitian\n",
    "    # TODO 4: Check if KKdagger equals its conjugate transpose\n",
    "    # KKdagger = ...\n",
    "    # property3 = np.allclose(...)\n",
    "    \n",
    "    # Property 4: (K† K) should be Hermitian\n",
    "    # TODO 5: Check if KdaggerK equals its conjugate transpose\n",
    "    # KdaggerK = ...\n",
    "    # property4 = np.allclose(...)\n",
    "    \n",
    "    print(\"\\nMoore-Penrose Property Verification:\")\n",
    "    print(f\"1. K K† K == K? {property1}\")\n",
    "    print(f\"2. K† K K† == K†? {property2}\")\n",
    "    print(f\"3. (K K†) is Hermitian? {property3}\")\n",
    "    print(f\"4. (K† K) is Hermitian? {property4}\")\n",
    "    \n",
    "    # Visualization of projection properties\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot eigenvalues of KK† (should be 0 or 1 for orthogonal projection)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # TODO 6: Compute eigenvalues of KKdagger\n",
    "    # eig_KKdagger = ...\n",
    "    plt.scatter(np.real(eig_KKdagger), np.imag(eig_KKdagger), c='b', alpha=0.7)\n",
    "    plt.title('Eigenvalues of KK†\\n(Should cluster near 0 and 1)')\n",
    "    plt.grid(True)\n",
    "    plt.axvline(x=0, color='r', linestyle='--', alpha=0.3)\n",
    "    plt.axvline(x=1, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Plot eigenvalues of K†K (should be 0 or 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # TODO 7: Compute eigenvalues of KdaggerK\n",
    "    # eig_KdaggerK = ...\n",
    "    plt.scatter(np.real(eig_KdaggerK), np.imag(eig_KdaggerK), c='g', alpha=0.7)\n",
    "    plt.title('Eigenvalues of K†K\\n(Should cluster near 0 and 1)')\n",
    "    plt.grid(True)\n",
    "    plt.axvline(x=0, color='r', linestyle='--', alpha=0.3)\n",
    "    plt.axvline(x=1, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663d470-1010-4d81-8c62-3c4fce35fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_pseudoinverse_properties()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371174b-826d-4f65-b620-4ce7cfd888d1",
   "metadata": {},
   "source": [
    "# Least-Squares and Minimum Norm Solutions\n",
    "\n",
    "Task: compute a least-squares solution for an overdetermined system\n",
    "- use SVD for pseudo-inverse\n",
    "- use normal equations for pseudo-inverse\n",
    "- check both approaches yield the same solution\n",
    "- plot contour of the residual and visualize the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612318b-39ef-4eca-bb7f-91ca92030be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overdetermined_system():\n",
    "    \"\"\"\n",
    "    Explore least-squares solution for an overdetermined system.\n",
    "    \n",
    "    Students should:\n",
    "    1. Compute the pseudo-inverse solution\n",
    "    2. Compute the least-squares solution via normal equations\n",
    "    3. Analyze and visualize the results\n",
    "    \"\"\"\n",
    "    # Create a simple overdetermined system\n",
    "    K = np.array([[1, 1], \n",
    "                  [2, 1], \n",
    "                  [1, 2]])\n",
    "    f = np.array([1, 1, 1])\n",
    "    \n",
    "    # TODO 1: Compute the pseudo-inverse solution\n",
    "    # K_dagger = ...\n",
    "    # u_pinv = ...\n",
    "    \n",
    "    # TODO 2: Compute least-squares solution using normal equations\n",
    "    # u_ls = ...\n",
    "    \n",
    "    # TODO 3: Calculate the residual norm\n",
    "    # residual = ...\n",
    "    \n",
    "    print(\"Overdetermined system (m > n):\")\n",
    "    print(f\"Pseudo-inverse solution: {u_pinv}\")\n",
    "    print(f\"Least-squares solution: {u_ls}\")\n",
    "    print(f\"Are they the same? {np.allclose(u_pinv, u_ls)}\")\n",
    "    print(f\"Residual norm: {residual}\")\n",
    "    \n",
    "    # Visualization (for 2D case only)\n",
    "    if K.shape[1] == 2:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        x = np.linspace(-1, 2, 100)\n",
    "        y = np.linspace(-1, 2, 100)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "        \n",
    "        # TODO 4: Compute residual over grid\n",
    "        # for i in range(len(x)):\n",
    "        #     for j in range(len(y)):\n",
    "        #         u = ...\n",
    "        #         Z[i, j] = ...\n",
    "        \n",
    "        plt.contourf(X, Y, Z, levels=20, cmap='viridis', alpha=0.8)\n",
    "        plt.colorbar(label='Residual norm')\n",
    "        plt.scatter(u_pinv[0], u_pinv[1], color='red', s=100, label='Solution')\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "        plt.title('Least-squares solution')\n",
    "        plt.xlabel('$u_1$')\n",
    "        plt.ylabel('$u_2$')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3cf00-611f-49c4-8899-736ee3bd2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "overdetermined_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212dd779-addc-44e5-9851-bf06605d85cd",
   "metadata": {},
   "source": [
    "# Minimum-norm solution for underdetermined systems\n",
    "\n",
    "Task: compute a minimum-norm solution for an underdetermined system\n",
    "- compute the min-norm solution with the pseudo-inverse\n",
    "- compute another solution\n",
    "- verify that both yield solutions and compare their norms\n",
    "- visualize both solutions along the set of all possible solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874413f4-dd1a-4815-b5fd-fc4398113ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def underdetermined_system():\n",
    "    \"\"\"\n",
    "    Explore minimum-norm solution for an underdetermined system.\n",
    "    \n",
    "    Students should:\n",
    "    1. Compute the pseudo-inverse solution\n",
    "    2. Generate an alternative solution\n",
    "    3. Compare solution norms and residuals\n",
    "    4. Visualize the solution space\n",
    "    \"\"\"\n",
    "    # Create a simple underdetermined system\n",
    "    K = np.array([[1, 1]])\n",
    "    f = np.array([1])\n",
    "    \n",
    "    # TODO 1: Compute the pseudo-inverse solution\n",
    "    # K_dagger = ...\n",
    "    # u_pinv = ...\n",
    "    \n",
    "    # TODO 2: Create another valid solution by adding a null space vector\n",
    "    # null_space_vector = ... (Hint: [1, -1] is in null(K))\n",
    "    # u_general = ...\n",
    "    \n",
    "    # TODO 3: Calculate residuals for both solutions\n",
    "    # residual_pinv = ...\n",
    "    # residual_general = ...\n",
    "    \n",
    "    print(\"Underdetermined system (m < n):\")\n",
    "    print(f\"Pseudo-inverse solution: {u_pinv}\")\n",
    "    print(f\"Another valid solution: {u_general}\")\n",
    "    print(f\"Residual for pseudo-inverse solution: {residual_pinv}\")\n",
    "    print(f\"Residual for general solution: {residual_general}\")\n",
    "    print(f\"Norm of pseudo-inverse solution: {np.linalg.norm(u_pinv)}\")\n",
    "    print(f\"Norm of general solution: {np.linalg.norm(u_general)}\")\n",
    "    \n",
    "    # Visualization (for 2D case only)\n",
    "    if K.shape[0] == 1 and K.shape[1] == 2:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        # Extract equation coefficients\n",
    "        a, b = K[0]\n",
    "        c = f[0]\n",
    "        \n",
    "        # TODO 4: Generate points for the solution line\n",
    "        # u1 = ...\n",
    "        # u2 = ... (handle case when b=0)\n",
    "        \n",
    "        plt.plot(u1, u2, 'b-', label='Solution space')\n",
    "        \n",
    "        # Plot solutions\n",
    "        plt.scatter(u_pinv[0], u_pinv[1], color='red', s=100, \n",
    "                   label='Minimum-norm solution')\n",
    "        plt.scatter(u_general[0], u_general[1], color='green', s=100,\n",
    "                   label='Other solution')\n",
    "        plt.scatter(0, 0, color='black', s=50, label='Origin')\n",
    "        \n",
    "        # TODO 5: Plot a circle showing the minimum norm\n",
    "        # r = ...\n",
    "        # theta = ...\n",
    "        # circle_x = ...\n",
    "        # circle_y = ...\n",
    "        # plt.plot(...)\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "        plt.title('Minimum-norm solution')\n",
    "        plt.xlabel('u_1')\n",
    "        plt.ylabel('u_2')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c1fea-933a-42e4-923f-a54a78be0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "underdetermined_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77db43-0c05-428a-8571-1a50c738ad85",
   "metadata": {},
   "source": [
    "# The Discrete Picard Condition\n",
    "Task: check the picard condition for a toy ill-posed problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84965e-a8d7-4aca-9e27-e2ebb04c49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_picard_condition(K, f, f_delta=None, sigma=None):\n",
    "    \"\"\"\n",
    "    Check if the discrete Picard condition is satisfied.\n",
    "    \n",
    "    Students should:\n",
    "    1. Compute the SVD of K\n",
    "    2. Calculate the projection coefficients\n",
    "    3. Plot and interpret the results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    K : ndarray\n",
    "        Forward operator matrix\n",
    "    f : ndarray\n",
    "        Exact data\n",
    "    f_delta : ndarray, optional\n",
    "        Noisy data\n",
    "    sigma : float, optional\n",
    "        Noise level\n",
    "    \"\"\"\n",
    "    # TODO 1: Compute the SVD of K\n",
    "    # U, s, Vh = ...\n",
    "    \n",
    "    # TODO 2: Compute projection coefficients for exact data\n",
    "    # coefs_exact = ...\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot singular values\n",
    "    plt.semilogy(range(len(s)), s, '*', label='σ_i (singular values)')\n",
    "    \n",
    "    # Plot exact coefficients (removed $ for non-math text)\n",
    "    plt.semilogy(range(len(coefs_exact)), coefs_exact, 'o', \n",
    "                label='|⟨u_i,f⟩| (exact)')\n",
    "    \n",
    "    # TODO 3: Handle noisy data case\n",
    "    if f_delta is not None:\n",
    "        # Compute coefficients for noisy data\n",
    "        # coefs_noisy = ...\n",
    "        plt.semilogy(range(len(coefs_noisy)), coefs_noisy, 'o', \n",
    "                    label='|⟨u_i,f^δ⟩| (noisy)')\n",
    "        \n",
    "        # TODO 4: Plot expected upper bound if sigma is provided\n",
    "        if sigma is not None:\n",
    "            # expected_bound = ...\n",
    "            plt.semilogy(range(len(expected_bound)), expected_bound, 'k--',\n",
    "                        label='Expected upper bound')\n",
    "    \n",
    "    plt.xlabel('i')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.ylim([1e-16, 2])\n",
    "    plt.xlim([0, len(s)])\n",
    "    plt.legend()\n",
    "    plt.title('Discrete Picard Condition Check')\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0dabe-7a2b-44b0-9928-3627d302ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ill_posed_problem_example():\n",
    "    \"\"\"Generate an ill-posed problem and check the Picard condition.\"\"\"\n",
    "    # Define forward operator (diagonal matrix with exponential decay)\n",
    "    n = 100\n",
    "    x = np.linspace(0, 1, n)\n",
    "    K = np.diag(np.exp(-5 * x))\n",
    "    \n",
    "    # Define ground truth and compute exact data\n",
    "    u = np.exp(-10 * x)\n",
    "    f = K @ u\n",
    "    \n",
    "    # Add noise\n",
    "    sigma = 1e-2\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    noise = np.random.randn(n)\n",
    "    f_delta = f + sigma * noise\n",
    "    \n",
    "    # Check Picard condition\n",
    "    check_picard_condition(K, f, f_delta, sigma)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4862e4-8049-421d-9b92-ced505d6f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "ill_posed_problem_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c680e6f-ed5c-4d66-b4cc-03ffb78127d1",
   "metadata": {},
   "source": [
    "# Connecting Image Deblurring to the Picard Condition\n",
    "Consider the code from the previous sheet that tried to deblur a noisy blurred image. Our naive approach failed even for small noise levels. How does this relate to the Picard condition? Hint: how are the Fourier coeffcients of Gaussian noise decaying? Are they decaying slower or faster than the Fourier coefficients of the Kernel?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIIP Course",
   "language": "python",
   "name": "aiip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
